# ğŸ§  Video Object Tracking with YOLOv8 + DeepSORT

This project implements a **real-time video object tracking system** using [YOLOv8](https://github.com/ultralytics/ultralytics) for detection and [DeepSORT](https://github.com/nwojke/deep_sort) for tracking. It supports training on MOT datasets, evaluating performance, and running on custom videos to track and identify pedestrians (or other objects).

---

## ğŸ“‚ Project Structure
```bash
video_object_tracking/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ MOT_YOLO/ # Preprocessed MOT dataset (images + labels)
â”‚ â”œâ”€â”€ pedestrian.mp4 # Example input video
â”œâ”€â”€ evaluation/
â”‚ â””â”€â”€ evaluate.py # Evaluation script
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ deep_sort_tracker.py
â”‚ â”œâ”€â”€ trainer.py
â”‚ â””â”€â”€ yolo_seg_detector.py
â”œâ”€â”€ outputs/ # Results: tracked videos, .txt outputs
â”œâ”€â”€ runs/ # YOLO training + detection outputs
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ main.py # Utility functions
â”œâ”€â”€ track_predict.py # Run tracking on any video
â”œâ”€â”€ train.py # Train YOLOv8 on MOT dataset
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Features

- ğŸ” **YOLOv8** for real-time object detection and segmentation
- ğŸ‘£ **DeepSORT** for multi-object tracking
- ğŸ“Š Train on custom MOT17-style datasets
- ğŸ¥ Track pedestrians (or other classes) in videos
- ğŸ§ª Output results in MOT format for evaluation

---

## ğŸ”§ Installation

1. **Clone the repository:**

```bash
git clone https://github.com/your-username/video_object_tracking.git
cd video_object_tracking
```

2. **Install dependencies:**

```bash
pip install -r requirements.txt
```

3. **Download YOLOv8 weights:**

```bash
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt
```

---

## ğŸ‹ï¸ Train on MOT Dataset
Ensure the dataset is structured like this:
```bash
data/MOT_YOLO/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â””â”€â”€ config.yaml
```
To start training:

```bash
python train.py
```

Update model path (yolov8n.pt, yolov8s.pt) and training parameters in train.py.

---

## ğŸ§ª Evaluate Trained Model

``` bash
python evaluation/evaluate.py
```

Generates bounding box predictions in MOT format and evaluates them (optionally).

---

## ğŸ“¹ Track Pedestrians in Video
Use your trained YOLOv8 model with DeepSORT on a video:

```bash
python track_predict.py \
  --video data/pedestrian.mp4 \
  --output_video outputs/output.mp4 \
  --output_txt outputs/output_mot.txt \
  --weights runs/train/yolov8n-mot17/weights/best.pt
```

This saves:

Annotated video with tracked objects

MOT-format .txt file with per-frame object positions

---

## ğŸ“Œ Output Format (MOT)
Each row in output_mot.txt:

```
frame_id, track_id, x, y, w, h, 1, -1, -1, -1
```

---

## ğŸ§  Model Architecture
YOLOv8: For fast object detection or segmentation.

YOLOSegDetector: Wrapper over YOLOv8 for detection.

DeepSORT: Tracks objects across frames using motion + appearance.

DeepSortTracker: Wrapper class that handles integration with detections.

---

## ğŸ›  TODO
 Add web UI for upload + tracking

 Add detection class filters

 ---

## ğŸ¤ Contributing
Open to suggestions, bug fixes, and feature contributions. PRs welcome!


